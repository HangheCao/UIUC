ğŸ“Š Independence Testing for Multivariate Data

A Comparative Study of Distance Correlation, HSIC, and Rank-Based Tests

ğŸ“˜ Overview

This project explores advanced independence testing methods for multivariate data, focusing on determining whether two sets of variables are statistically related.
Four tests were implemented from scratch â€” Distance Correlation (DCOR), Hilbert-Schmidt Independence Criterion (HSIC), Sum of Rank Correlations (SRC), and Maxima of Rank Correlations (MRC) â€” and compared through simulation and real-world applications.

The study combines theory, simulation, and data analysis to determine which methods perform best in low- and high-dimensional settings.
Applications include both prostate cancer data (biomedical context) and customer purchase records (business context).

ğŸ¯ Objectives

Implement four independence tests from scratch in R.

Evaluate each method through simulation and real data.

Compare tests based on Type I error, power, parameter sensitivity, and efficiency.

Recommend appropriate tests for different dimensional settings and application domains.

ğŸ§® Methods Implemented
ğŸ”¹ Distance Correlation (DCOR)

Measures association between multivariate random vectors.

Captures both linear and nonlinear dependencies.

Performs best for low-dimensional data.

ğŸ”¹ Hilbert-Schmidt Independence Criterion (HSIC)

Kernel-based test using Gaussian kernels.

Excels at detecting complex nonlinear patterns in high-dimensional data.

Sensitive to kernel width parameter (ÏƒÂ²); optimal near the median pairwise distance.

ğŸ”¹ Sum of Rank Correlations (SRC)

Aggregates Spearman rank correlations across all variable pairs.

Simple and interpretable, but less powerful in complex relationships.

ğŸ”¹ Maxima of Rank Correlations (MRC)

Focuses on the strongest individual pairwise correlation.

Useful for detecting dominant relationships, though less stable under noise.

âš™ï¸ Simulation Results
Scenario	Best Performing Test	Key Observations
Low-dimensional (dX = dY = 2)	Distance Correlation (DCOR)	Stable Type I â‰ˆ 2%, power â‰ˆ 100%
High-dimensional (dX = dY = 10)	Hilbert-Schmidt Independence Criterion (HSIC)	Excellent error control â‰ˆ 0%, power â‰ˆ 100%
Parameter Sensitivity	HSIC	Requires careful ÏƒÂ² tuning
Computation	DCOR & HSIC	Most efficient and stable

âœ… Recommendation

Use DCOR for small, interpretable datasets.

Use HSIC for high-dimensional or nonlinear relationships (e.g., marketing, genomics).

ğŸ“Š Real Data Applications
ğŸ§¬ Prostate Cancer Dataset

Testing dependence between biological and demographic variables:


X={lpsa, lcavol, lweight}

Y={age, lbph, lcp}

All four tests (DCOR, HSIC, SRC, MRC) rejected independence, showing strong relationships between cancer indicators and patient characteristics.

ğŸ›’ Customer Purchase Data

Analyzed relationships between customer purchase patterns and economic/demographic indicators.

HSIC was the most effective at uncovering nonlinear dependencies.

Offers reliable and computationally efficient insight for business decision-making.

ğŸ’¡ Key Takeaways

DCOR â†’ Best for low-dimensional, interpretable data.

HSIC â†’ Best for complex, high-dimensional relationships.

SRC/MRC â†’ Simpler rank-based options but lower statistical power.

HSIC provides robust, efficient, and scalable independence detection for real-world data.

ğŸ§° Tools & Implementation
Category	Details
Language	R
Key Libraries	stats, Matrix, ggplot2
Approach	Manual implementation of test statistics and permutation tests
Data Sources	1ï¸âƒ£ Prostate Cancer Dataset (Hastie et al.)â€ƒ2ï¸âƒ£ Synthetic Customer Purchase Data
